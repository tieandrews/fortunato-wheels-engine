{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Price Modelling & Analysis\n",
    "\n",
    "This notebook contains the initial exploration of modelling approaches to tackle the following challenges:\n",
    "\n",
    "1. A user is looking for a specific make/model of car and wants to know how much it might cost.\n",
    "2. A user is looking for a specific type of car and wondering what makes/models fit within that range (e.g. SUV, mini-van, truck)\n",
    "\n",
    "The results should be easily interpretable by users. Expected user flow is as follows:\n",
    "\n",
    "1. User is looking for make/model\n",
    "   1. User comes to the site\n",
    "   2. Selects type of vehicle they're looking for\n",
    "      - From: SUV, Truck, Van, Sedan, Sports Car\n",
    "   3. After that they can select a make/model if they want but is optional and will show info for average price by make and/or model (?)\n",
    "   4. They can put in a desired age of vehicle in years as well as desired mileage range but is optional.\n",
    "   5. With the inputs entered the following cases are displayed:\n",
    "       - Just type of vehicle: a break down by make is shown with price by age of vehicle\n",
    "       - Type of vehicle and make: a break down by model of vehicle price and age of vehicle\n",
    "       - Type/make/model: details on price by age as well as mileage\n",
    "       - Type/budget price: find for all makes and models the age that is closest to the budget amount how to optimize for both age and mileage? Have milage per year perhaps?\n",
    "         - Possibly leave out mileage and include the average mileapge per year plus conf. interval to say this age with ~ X-Y km's?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import plotly.express as px\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK, Trials\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "SRC_PATH = cur_dir[: cur_dir.index(\"fortunato-wheels-engine\") + len(\"fortunato-wheels-engine\")]\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.append(SRC_PATH)\n",
    "\n",
    "from src.data.car_ads import CarAds\n",
    "from src.logs import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "AZURE_MLFLOW_URI = os.environ.get(\"AZURE_MLFLOW_URI\")\n",
    "mlflow.set_tracking_uri(AZURE_MLFLOW_URI)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set(rc={\"figure.figsize\": (8, 12)})\n",
    "# set context to notebook\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "plt.rcParams[\"font.family\"] = \"sans serif\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = CarAds()\n",
    "# ads.get_car_ads(sources=[\"cargurus\", \"kijiji\"])\n",
    "ads.get_car_ads(data_dump=os.path.join(SRC_PATH, \"data\", \"processed\", \"car-ads-dump_2023-07-18.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.preprocess_ads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save preprocessed data to parquet\n",
    "# output_path = os.path.join(SRC_PATH, \"data\", \"processed\", \"car-ads-dump_2023-07-18.csv\")\n",
    "\n",
    "# ads.export_to_csv(output_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "What are the most common manufacturers and models of vehicles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a single plot with two plots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 12))\n",
    "\n",
    "# only plot the top 15 makes\n",
    "sns.countplot(\n",
    "    y=\"make\", data=ads.df, order=ads.df[\"make\"].value_counts().iloc[:10].index, ax=ax1,\n",
    "    palette=\"winter\"\n",
    ")\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "ax1.set_xlabel(\"Number of Ads\")\n",
    "ax1.set_ylabel(\"Make\")\n",
    "# remove the x ax1is tick labels\n",
    "ax1.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n",
    "ax1.set_title(\n",
    "    \"Top 10 Manufacturers by Number of Ads in the\\nFortunato Wheels DataBase\", fontsize=23\n",
    ")\n",
    "\n",
    "# add the number of ads at the right of each bar divided by 1000\n",
    "for p in ax1.patches:\n",
    "    width = p.get_width()\n",
    "    ax1.text(\n",
    "        width + 1000,\n",
    "        p.get_y() + p.get_height() / 2 + 0.1,\n",
    "        \"{:1.0f}\".format(width / 1000) + \"k\",\n",
    "        ha=\"left\",\n",
    "    )\n",
    "\n",
    "# only plot the top 15 makes\n",
    "sns.countplot(\n",
    "    y=\"model\", data=ads.df, order=ads.df[\"model\"].value_counts().iloc[:10].index, ax=ax2,\n",
    "    palette=\"winter\"\n",
    ")\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "ax2.set_xlabel(\"Number of Ads\")\n",
    "ax2.set_ylabel(\"Model\")\n",
    "# remove the x ax2is tick labels\n",
    "ax2.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n",
    "ax2.set_title(\n",
    "    \"Top 10 Models by Number of Ads in the\\nFortunato Wheels DataBase\", fontsize=23\n",
    ")\n",
    "\n",
    "# add the number of ads at the right of each bar divided by 1000\n",
    "for p in ax2.patches:\n",
    "    width = p.get_width()\n",
    "    ax2.text(\n",
    "        width + 1000,\n",
    "        p.get_y() + p.get_height() / 2 + 0.1,\n",
    "        \"{:1.0f}\".format(width / 1000) + \"k\",\n",
    "        ha=\"left\",\n",
    "    )\n",
    "\n",
    "# add spacing between the two plots\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the reported condition on most cars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.df.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot number of ads posted per month from 2015-2023\n",
    "fig, ax = plt.subplots(figsize=(24, 12))\n",
    "sns.countplot(\n",
    "    x=ads.df.listed_date.dt.year,\n",
    "    hue=ads.df.listed_date.dt.month,\n",
    "    data=ads.df,\n",
    "    palette=\"winter\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Number of Ads\")\n",
    "ax.set_title(\"Number of Ads Posted per Month from 2015-2023\", fontsize=23)\n",
    "ax.legend(\n",
    "    title=\"Month\",\n",
    "    loc=\"upper left\",\n",
    "    labels=[\n",
    "        \"January\",\n",
    "        \"February\",\n",
    "        \"March\",\n",
    "        \"April\",\n",
    "        \"May\",\n",
    "        \"June\",\n",
    "        \"July\",\n",
    "        \"August\",\n",
    "        \"September\",\n",
    "        \"October\",\n",
    "        \"November\",\n",
    "        \"December\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the number of ads available per year?\n",
    "fig, ax = plt.subplots(figsize=(24, 12))\n",
    "sns.countplot(x=ads.df.listed_date.dt.year, data=ads.df, palette=\"winter\")\n",
    "\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Number of Ads\")\n",
    "ax.set_title(\"Number of Ads Posted per Year from 2015-2023\", fontsize=23)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How has the price of Honda Civicc, Ford F-150, and Nissan Rigue changed over time?\n",
    "# make a plot of price over time for each of the three models on the same plot\n",
    "\n",
    "# resample prices and get the mean price for each month for each of Honda Civic, Ford F-150, and Nissan Rogue\n",
    "# and the number of ads for each month for each of Honda Civic, Ford F-150, and Nissan Rogue\n",
    "ads.df.ad_id.fillna(-1, inplace=True)\n",
    "price_df = (\n",
    "    ads.df[\n",
    "        # ads.df.make.isin([\"Civic\", \"F-150\", \"Rogue\"])\n",
    "        (ads.df.condition == \"Used\")\n",
    "        & (ads.df.listed_date.dt.year >= 2022)\n",
    "        & (ads.df.listed_date.dt.year <= 2024)\n",
    "    ]\n",
    "    .groupby([pd.Grouper(key=\"listed_date\", freq=\"M\")]) # \"model\", \n",
    "    # aggregate by mean price and count the number of ads in each quarter\n",
    "    .agg({\"price\": \"mean\", \"ad_id\": \"count\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# make a single plot with two plots side by side\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "\n",
    "# only plot the top 15 makes\n",
    "sns.lineplot(\n",
    "    x=\"listed_date\",\n",
    "    y=\"price\",\n",
    "    data=price_df[price_df.ad_id > 10],\n",
    "    markers=True,\n",
    "    marker=\"o\",\n",
    "    color=\"#0d6efd\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(\"Year-Month\")\n",
    "ax.set_ylabel(\"Avg. Used Car Price ($CAD)\")\n",
    "ax.set_title(\n",
    "    \"Average Used Car Price is Down ~45% from 2022 Peak\\n \",\n",
    "    fontsize=26,\n",
    ")\n",
    "ax.set_ylim(bottom=0, top=price_df.price.max() * 1.15)\n",
    "ax.set_xlim(\n",
    "    left=price_df.listed_date.min(), right=price_df.listed_date.max()\n",
    ")\n",
    "# fill the area below the line plot with 0.5 opacity area\n",
    "ax.fill_between(\n",
    "    price_df.listed_date,\n",
    "    price_df.price,\n",
    "    color=\"#0d6efd\",\n",
    "    alpha=0.3,\n",
    "    label=None\n",
    ")\n",
    "\n",
    "# put a text and marker at the highest average used car price\n",
    "ax.annotate(\n",
    "    f\"Peak Avg. Used Car Price:\\n${price_df.price.max()/1000:.0f}k CAD\",\n",
    "    xy=(price_df.listed_date[price_df.price.idxmax()], price_df.price.max()),\n",
    "    xytext=(price_df.listed_date[price_df.price.idxmax()], price_df.price.max() * 1.05),\n",
    "    arrowprops=dict(facecolor=\"black\", shrink=0.05),\n",
    "    fontsize=18,\n",
    "    weight=\"bold\",\n",
    "    horizontalalignment=\"center\",\n",
    ")\n",
    "\n",
    "# annotate used price as of July 2023\n",
    "ax.annotate(\n",
    "    f\"July 2023\\nAvg. Used Car Price:\\n${price_df.price.iloc[-2]/1000:.0f}k CAD\",\n",
    "    xy=(price_df.listed_date.iloc[-2], price_df.price.iloc[-2]),\n",
    "    xytext=(price_df.listed_date.iloc[-2], price_df.price.iloc[-2] * 1.15),\n",
    "    arrowprops=dict(facecolor=\"black\", shrink=0.05),\n",
    "    fontsize=18,\n",
    "    weight=\"bold\",\n",
    "    horizontalalignment=\"right\",\n",
    ")\n",
    "\n",
    "\n",
    "# make plot tight layout\n",
    "# plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = (\n",
    "    ads.df[\n",
    "        ads.df.condition.isin([\"Used\", \"New\"])\n",
    "        & (ads.df.listed_date > \"2023-02-15\")\n",
    "        & (ads.df.listed_date.dt.year <= 2024)\n",
    "    ]\n",
    "    .groupby([\"condition\", pd.Grouper(key=\"listed_date\", freq=\"SM\")]) # \"model\", \n",
    "    # aggregate by count of ads in each month as column named ad_count\n",
    "    .agg({\"ad_id\": \"count\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# make a single plot with two plots side by side\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "\n",
    "# only plot the top 15 makes\n",
    "sns.lineplot(\n",
    "    x=\"listed_date\",\n",
    "    y=\"ad_id\",\n",
    "    hue=\"condition\",\n",
    "    data=price_df,\n",
    "    markers=True,\n",
    "    marker=\"o\",\n",
    "    # set colors for each line\n",
    "    palette={\"Used\": \"#0d6efd\", \"New\": \"#198754\"},\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(\"Year-Month\")\n",
    "ax.set_ylabel(\"No. of Car Ads Posted\")\n",
    "ax.set_title(\n",
    "    \"New & Used Car Ads being Posted Are Decreasing in 2023\\n \",\n",
    "    fontsize=26,\n",
    ")\n",
    "# ax.set_ylim(bottom=0, top=price_df.price.max() * 1.15)\n",
    "ax.set_xlim(\n",
    "    left=price_df.listed_date.min(), right=price_df.listed_date.max()\n",
    ")\n",
    "# rotate x lables to 30 degrees\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha=\"right\")\n",
    "# fill the area below the line plot with 0.5 opacity area\n",
    "# ax.fill_between(\n",
    "#     price_df.listed_date,\n",
    "#     price_df.price,\n",
    "#     color=\"#0d6efd\",\n",
    "#     alpha=0.3,\n",
    "#     label=None\n",
    "# )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix ads.df where if location is a list containing a single dict, convert to dict\n",
    "ads.df.location = ads.df.location.apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "ads.df.loc[ads.df.source == \"kijiji\", \"province\"] = ads.df[ads.df.source == \"kijiji\"].location.apply(lambda x: x[\"stateProvince\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.df[ads.df.source == \"kijiji\"].location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix ads.df where if location is a list containing a single dict, convert to dict\n",
    "ads.df.location = ads.df.location.apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "ads.df.loc[ads.df.source == \"kijiji\", \"province\"] = (\n",
    "    ads.df[ads.df.source == \"kijiji\"]\n",
    "    .location.apply(lambda x: x[\"stateProvince\"])\n",
    ")\n",
    "\n",
    "ads_by_province = (\n",
    "    ads.df[ads.df.source == \"kijiji\"]\n",
    "    # extract stateProvince from location column as new column province\n",
    "    .assign(province=lambda x: x.location.apply(lambda x: x[\"stateProvince\"]))\n",
    "    # group by province and count the number of ads in each province\n",
    "    .groupby(\"province\")\n",
    "    .agg({\"ad_id\": \"count\"})\n",
    "    .reset_index()\n",
    "    .sort_values(\"ad_id\", ascending=False)\n",
    ")\n",
    "\n",
    "ads_by_province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what provinces have the most ads posted?\n",
    "fig, ax = plt.subplots(figsize=(24, 12))\n",
    "sns.barplot(\n",
    "    x=\"province\",\n",
    "    y=\"ad_id\",\n",
    "    data=ads_by_province.head(10),\n",
    "    # order=ads_by_province[\"province\"].value_counts().iloc[:10].index,\n",
    "    palette=\"winter\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Province\")\n",
    "ax.set_ylabel(\"Number of Ads\")\n",
    "ax.set_title(\"Top 10 Provinces by Number of Ads in the\\nFortunato Wheels DataBase\", fontsize=23)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price Prediction for for All Makes/Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ads_for_training(\n",
    "        ads_df:pd.DataFrame,\n",
    "        model_features = [\n",
    "            \"age_at_posting\",\n",
    "            \"mileage_per_year\",\n",
    "            \"make\",\n",
    "            \"model\",\n",
    "            \"wheel_system\",\n",
    "        ],\n",
    "        min_num_ads = 1000,\n",
    "        max_age_at_posting = 20,\n",
    "        min_price = 1000,\n",
    "        max_price = 250000,\n",
    "    ):\n",
    "\n",
    "    logger.info(f\"Preprocessing ads for training, starting with {len(ads_df)} ads\")\n",
    "\n",
    "    if \"model\" not in model_features:\n",
    "        model_features.append(\"model\")\n",
    "\n",
    "    if \"price\" not in model_features:\n",
    "        model_features = model_features + [\"price\"]\n",
    "\n",
    "    preprocessed_df = ads_df[model_features].copy()\n",
    "\n",
    "    # remove models with less than min_num_ads\n",
    "    model_counts = preprocessed_df[\"model\"].value_counts()\n",
    "    models_to_keep = model_counts[model_counts > min_num_ads].index\n",
    "    preprocessed_df = preprocessed_df[preprocessed_df[\"model\"].isin(models_to_keep)]\n",
    "\n",
    "    # remove NaN models and \"other\"\n",
    "    preprocessed_df = preprocessed_df[~preprocessed_df[\"model\"].isna()]\n",
    "    preprocessed_df = preprocessed_df[preprocessed_df[\"model\"].str.lower() != \"other\"]\n",
    "\n",
    "    # remove ads with prices outside of min_price and max_price\n",
    "    preprocessed_df = preprocessed_df.query(\"price > @min_price & price < @max_price\")\n",
    "\n",
    "    if \"age_at_posting\" in model_features:\n",
    "        # remove cars older than max_age_at_posting years\n",
    "        preprocessed_df = preprocessed_df[preprocessed_df[\"age_at_posting\"] <= max_age_at_posting]\n",
    "\n",
    "    if \"wheel_system\" in model_features:\n",
    "        # replace NaN wheel_system with \"unknown\"\n",
    "        preprocessed_df[\"wheel_system\"] = preprocessed_df[\"wheel_system\"].fillna(\"unknown\")\n",
    "\n",
    "    if \"mileage_per_year\" in model_features:\n",
    "        # where ads have an age_at_posting of zero set mileage_per_year to 0\n",
    "        preprocessed_df.loc[preprocessed_df[\"age_at_posting\"] == 0, \"mileage_per_year\"] = 0\n",
    "        # drop any other mileage per year NaNs\n",
    "        preprocessed_df = preprocessed_df[~preprocessed_df[\"mileage_per_year\"].isna()]\n",
    "\n",
    "    logger.info(f\"Preprocessing ads for training, ending with {len(preprocessed_df)} ads\")\n",
    "\n",
    "    return preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = [\n",
    "    \"age_at_posting\",\n",
    "    \"mileage_per_year\",\n",
    "    \"make\",\n",
    "    \"model\",\n",
    "    \"price\",\n",
    "    \"wheel_system\",\n",
    "    # \"province\"\n",
    "]\n",
    "\n",
    "preprocessed_ads = preprocess_ads_for_training(ads.df, model_features=model_features)\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    preprocessed_ads,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=preprocessed_ads[\"model\"],\n",
    ")\n",
    "\n",
    "# with features selected drop all with null values\n",
    "train_df = train_df[model_features].dropna().reset_index(drop=True)\n",
    "test_df = test_df[model_features].dropna().reset_index(drop=True)\n",
    "\n",
    "X_train = train_df.drop(columns=[\"price\"])\n",
    "y_train = train_df[\"price\"]\n",
    "X_test = test_df.drop(columns=[\"price\"])\n",
    "y_test = test_df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot how many ads there are by the top make_name values\n",
    "fig = px.histogram(\n",
    "    # ads.loc[ads.make_name.isin(ads.make_name.value_counts().index[:15])],\n",
    "    train_df.loc[train_df.model.isin(train_df.model.value_counts().index[:60])],\n",
    "    x=\"model\",\n",
    "    title=\"Number of Ads by Model\",\n",
    "    color=\"model\",\n",
    "    labels={\"model\": \"Model\"},\n",
    "    color_discrete_sequence=px.colors.qualitative.Dark24,\n",
    "    height=500,\n",
    "    category_orders={\"model\": train_df.model.value_counts().index[:60]}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"age_at_posting\", \"mileage_per_year\"]\n",
    "\n",
    "categorical_features = [\"model\", \"wheel_system\", \"make\"] #, \"province\"]\n",
    "\n",
    "# make column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines: Dummy Regressor & Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {}\n",
    "metrics = [\"neg_root_mean_squared_error\", \"r2\", \"neg_mean_absolute_percentage_error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipeline\n",
    "dummy_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", DummyRegressor()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# run cross_validation on dummy regressor\n",
    "model_results[\"dummy\"] = pd.DataFrame(cross_validate(\n",
    "    dummy_pipe,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=metrics,\n",
    "    return_train_score=True,\n",
    ")).agg([\"mean\", \"std\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipeline\n",
    "linreg_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", Ridge()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# run cross_validation on dummy regressor\n",
    "model_results[\"ridge\"] = pd.DataFrame(cross_validate(\n",
    "    linreg_pipe,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=metrics,\n",
    "    return_train_score=True,\n",
    ")).agg([\"mean\", \"std\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat( \n",
    "    model_results,\n",
    "    axis='columns'  # Get the right model names and mean/std as columns \n",
    ").xs( \n",
    "    'mean',  # Select only the 'std' columns \n",
    "    axis='columns',  # Cross-section the columns \n",
    "    level=1  # The 1st level ('mean', 'std') instead of the 0th level (the model names) \n",
    ").style.format( \n",
    "    precision=4  # Pandas `.style` does not honor previous rounding via `.round()` \n",
    ").background_gradient( \n",
    "    axis=None  # Color cells based on the entire matrix rather than row/column-wise \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results[\"ridge\"].loc[\"test_\" + metrics[0]][\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Hyperopt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"neg_root_mean_squared_error\", \"r2\", \"neg_mean_absolute_percentage_error\"]\n",
    "\n",
    "def objective(params):\n",
    "    classifier_type = params['type']\n",
    "    del params['type']\n",
    "    if classifier_type == 'gradient_boosting':\n",
    "        clf = GradientBoostingRegressor(**params)\n",
    "    elif classifier_type == 'xgboost':\n",
    "        clf = XGBRegressor(**params)\n",
    "    elif classifier_type == 'rf':\n",
    "        clf = RandomForestRegressor(**params)\n",
    "    elif classifier_type == 'ridge':\n",
    "        clf = Ridge(**params)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"regressor\", clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # manually run cross_validate and get train/test rmse, mape, and r2\n",
    "    model_cv_results = pd.DataFrame(cross_validate(\n",
    "        pipe,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=5,\n",
    "        scoring=metrics,\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1,\n",
    "    )).agg([\"mean\", \"std\"]).T\n",
    "\n",
    "\n",
    "    # log metrics to mlflow\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        # log train and test for each metric\n",
    "        for m in metrics:\n",
    "            mlflow.log_metric(f\"{m}_train_mean\", model_cv_results.loc[f\"train_{m}\"][\"mean\"])\n",
    "            mlflow.log_metric(f\"{m}_test_mean\", model_cv_results.loc[f\"test_{m}\"][\"mean\"])\n",
    "            mlflow.log_metric(f\"{m}_train_std\", model_cv_results.loc[f\"train_{m}\"][\"std\"])\n",
    "            mlflow.log_metric(f\"{m}_test_std\", model_cv_results.loc[f\"test_{m}\"][\"std\"])\n",
    "\n",
    "        # log params\n",
    "        mlflow.log_params(params)\n",
    "        # log the type of model\n",
    "        mlflow.log_param(\"model_type\", classifier_type)\n",
    "\n",
    "        fit_model = pipe.fit(X_train, y_train)\n",
    "\n",
    "        # log model\n",
    "        mlflow.sklearn.log_model(fit_model, \"model\", signature=infer_signature(X_train, y_train))\n",
    "\n",
    "    # make negative rmse positive so it minimizes it\n",
    "    result = { 'loss': -model_cv_results.loc[\"test_\" + metrics[0]][\"mean\"], 'status': STATUS_OK}\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make column transformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "search_space = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'type': 'gradient_boosting',\n",
    "        'max_features': hp.choice('max_features', ['sqrt', 'log2']),\n",
    "        'max_depth': hp.uniformint('max_depth', 15, 30),\n",
    "        'min_samples_split': hp.uniformint('dtree_min_samples_split', 20, 40),\n",
    "        'n_estimators': hp.uniformint('n_estimators', 150, 300),\n",
    "    },\n",
    "    # {\n",
    "    #     'type': 'rf',\n",
    "    #     'max_depth': hp.uniformint('max_depth', 5, 50),\n",
    "    #     'max_features': hp.choice('max_features', ['sqrt', 'log2']),\n",
    "    #     'min_samples_split': hp.uniform('min_samples_split', 0.1, 1),\n",
    "    # },\n",
    "    # {\n",
    "    #     'type': 'ridge',\n",
    "    #     'alpha': hp.uniform('alpha', 0.1, 100),\n",
    "    # }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"price-prediction-v2-gradboost\")\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "\n",
    "search_algorithm = tpe.suggest\n",
    "\n",
    "best_hyperparams = fmin(\n",
    "fn=objective, \n",
    "space=search_space,\n",
    "algo=search_algorithm,\n",
    "max_evals=2,\n",
    "trials= Trials())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hist Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"neg_root_mean_squared_error\", \"r2\", \"neg_mean_absolute_percentage_error\"]\n",
    "\n",
    "def objective(params):\n",
    "    classifier_type = params['type']\n",
    "    del params['type']\n",
    "    if classifier_type == 'hist_grad_boost':\n",
    "        clf = HistGradientBoostingRegressor(**params)\n",
    "    elif classifier_type == 'xgboost':\n",
    "        clf = XGBRegressor(**params)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", hist_preprocessor),\n",
    "            (\"regressor\", clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # manually run cross_validate and get train/test rmse, mape, and r2\n",
    "    model_cv_results = pd.DataFrame(cross_validate(\n",
    "        pipe,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=5,\n",
    "        scoring=metrics,\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1,\n",
    "    )).agg([\"mean\", \"std\"]).T\n",
    "\n",
    "\n",
    "    # log metrics to mlflow\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        # log train and test for each metric\n",
    "        for m in metrics:\n",
    "            mlflow.log_metric(f\"{m}_train_mean\", model_cv_results.loc[f\"train_{m}\"][\"mean\"])\n",
    "            mlflow.log_metric(f\"{m}_test_mean\", model_cv_results.loc[f\"test_{m}\"][\"mean\"])\n",
    "            mlflow.log_metric(f\"{m}_train_std\", model_cv_results.loc[f\"train_{m}\"][\"std\"])\n",
    "            mlflow.log_metric(f\"{m}_test_std\", model_cv_results.loc[f\"test_{m}\"][\"std\"])\n",
    "\n",
    "        # log params\n",
    "        mlflow.log_params(params)\n",
    "        # log the type of model\n",
    "        mlflow.log_param(\"model_type\", classifier_type)\n",
    "\n",
    "        fit_model = pipe.fit(X_train, y_train)\n",
    "\n",
    "        # log model\n",
    "        mlflow.sklearn.log_model(fit_model, \"model\", signature=infer_signature(X_train, y_train))\n",
    "\n",
    "    # make negative rmse positive so it minimizes it\n",
    "    result = { 'loss': -model_cv_results.loc[\"test_\" + metrics[0]][\"mean\"], 'status': STATUS_OK}\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make column transformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "hist_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(sparse_output=True, handle_unknown=\"ignore\"), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "search_space = hp.choice('classifier_type', [\n",
    "    # {\n",
    "    #     'type': 'hist_grad_boost',\n",
    "    #     \"max_iter\": hp.uniformint(\"max_iter\", 50, 300),\n",
    "    #     'max_bins': hp.uniformint('max_bins', 50, 255),\n",
    "    #     'max_depth': hp.uniformint('max_depth', 10, 30),\n",
    "    #     'min_samples_leaf': hp.uniformint('min_samples_leaf', 10, 30),\n",
    "    #     # \"categorical_features\": hp.choice(\"categorical_features\", [[False, False, True, True, True, True]]),\n",
    "    # },\n",
    "    {\n",
    "        'type': 'xgboost',\n",
    "        'max_depth': hp.uniformint('max_depth', 15, 40),\n",
    "        'min_child_weight': hp.uniformint('min_child_weight', 1, 10),\n",
    "        'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "        'n_estimators': hp.uniformint('n_estimators', 150, 400),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "        'gamma': hp.uniform('gamma', 0.1, 1),\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"price-prediction-v2-xgboost\")\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "\n",
    "search_algorithm = tpe.suggest\n",
    "\n",
    "best_hyperparams = fmin(\n",
    "fn=objective, \n",
    "space=search_space,\n",
    "algo=search_algorithm,\n",
    "max_evals=400,\n",
    "trials= Trials())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train final model with best hyperparmetes and log to mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'max_features': \"log2\",\n",
    "        'max_depth': 25,\n",
    "        'min_samples_split': 35,\n",
    "        'n_estimators': 400\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"price-prediction-v1\")\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", GradientBoostingRegressor(**params)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# manually run cross_validate and get train/test rmse, mape, and r2\n",
    "model_cv_results = pd.DataFrame(cross_validate(\n",
    "    pipe,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=metrics,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    ")).agg([\"mean\", \"std\"]).T\n",
    "\n",
    "\n",
    "# log metrics to mlflow\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # log train and test for each metric\n",
    "    for m in metrics:\n",
    "        mlflow.log_metric(f\"{m}_train_mean\", model_cv_results.loc[f\"train_{m}\"][\"mean\"])\n",
    "        mlflow.log_metric(f\"{m}_test_mean\", model_cv_results.loc[f\"test_{m}\"][\"mean\"])\n",
    "        mlflow.log_metric(f\"{m}_train_std\", model_cv_results.loc[f\"train_{m}\"][\"std\"])\n",
    "        mlflow.log_metric(f\"{m}_test_std\", model_cv_results.loc[f\"test_{m}\"][\"std\"])\n",
    "\n",
    "    # log params\n",
    "    mlflow.log_params(params)\n",
    "    # log the type of model\n",
    "    mlflow.log_param(\"model_type\", \"gradient_boosting\")\n",
    "\n",
    "    fit_model = pipe.fit(X_train, y_train)\n",
    "\n",
    "    # log model\n",
    "    mlflow.sklearn.log_model(fit_model, \"model\", signature=infer_signature(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"price-prediction-quantiles-v1\")\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "import time\n",
    "\n",
    "params = {\n",
    "        'max_features': \"log2\",\n",
    "        'max_depth': 25,\n",
    "        'min_samples_split': 35,\n",
    "        'n_estimators': 400,\n",
    "        \"loss\": \"quantile\",\n",
    "    }\n",
    "\n",
    "# log metrics to mlflow\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # log params\n",
    "    mlflow.log_params(params)\n",
    "    # log the type of model\n",
    "    mlflow.log_param(\"model_type\", \"quant_gradient_boosting\")\n",
    "\n",
    "    for a in [0.05, 0.95]:\n",
    "\n",
    "        pipe = Pipeline(\n",
    "            steps=[\n",
    "                (\"preprocessor\", preprocessor),\n",
    "                (\"regressor\", GradientBoostingRegressor(alpha=a, **params)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(f\"Fitting q{a}...\")\n",
    "        start_time = time.time()\n",
    "        fit_model = pipe.fit(X_train, y_train)\n",
    "        print(f\"Done fitting, took {time.time() - start_time:.0f}s, logging model...\")\n",
    "        # log model\n",
    "        mlflow.sklearn.log_model(fit_model, f\"model_q{a*100:.0f}\", signature=infer_signature(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv the makes/models used in the model to be loaded in the website\n",
    "X_train[[\"make\", \"model\"]].drop_duplicates().to_csv(\n",
    "    os.path.join(SRC_PATH, \"models\", \"prediction-vehicle-make-model-config.csv\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.make.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model with Trim Options and Description\n",
    "\n",
    "To try and improve the model performance, we will try to include the trim options and description of the vehicle in the model. \n",
    "\n",
    "The kijiji ads options are in the `features` column, where as cargurus ads options are in the `major_options` column. Depending on if the data is loaded from MongoDB or from CSV the list of options can either be string or list. List is preferred to explode the options into a row for each option then only collect the most common ones.\n",
    "\n",
    "The code below is a work in progress and has the following bugs remaining as of July 21, 2023\n",
    "- the function `get_car_options` is dropping some of the columns of the dataframe like `source`, don't know why, think it has something to do with how it handles empty/nan rows/values\n",
    "- the cargurus ads don't have unique ad id's attached, so the index is reset and treated as a unique id for analysis purposes, this should be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_car_options(ads_df:pd.DataFrame, top_n_options:int=50):\n",
    "    \"\"\"\n",
    "    Get the car options from the major_options column in the ads dataframe\n",
    "    and return a dataframe with the options one hot encoded\n",
    "    \"\"\"\n",
    "\n",
    "    ads_df[\"options_list\"] = None\n",
    "\n",
    "    # parse cargurus strings of options into list of options\n",
    "    ads_df.loc[ads_df.source == \"cargurus\", \"options_list\"] = (\n",
    "        ads_df.loc[ads_df.source == \"cargurus\", \"major_options\"]\n",
    "        .str.strip(\"['']\")\n",
    "        .str.replace(\"'\", \"\")\n",
    "        .str.replace(\", \", \",\")\n",
    "        .str.replace(\" \", \"-\")\n",
    "        .str.replace(\"/\", \"-\")\n",
    "        .str.lower()\n",
    "        .str.split(\",\")\n",
    "    )\n",
    "\n",
    "    ads_df.loc[ads_df.source == \"kijiji\", \"options_list\"] = (\n",
    "        ads_df.loc[ads_df.source == \"kijiji\", \"features\"]\n",
    "        .str.strip(\"['']\")\n",
    "        .str.replace(\"'\", \"\")\n",
    "        .str.replace(\", \", \",\")\n",
    "        .str.replace(\" \", \"-\")\n",
    "        .str.replace(\"/\", \"-\")\n",
    "        .str.lower()\n",
    "        .str.split(\",\")\n",
    "    )\n",
    "\n",
    "    # reset the index to use as uniqwue id's for each ad as cargurus doesn't have unique id's\n",
    "    ads_df = ads_df.reset_index().rename(columns={\"index\": \"unique_id\"})\n",
    "\n",
    "    car_options_df = ads_df.explode(\"options_list\")\n",
    "\n",
    "    # explode the major_options column but only keep the top n options by count\n",
    "    most_common_options = (\n",
    "        car_options_df\n",
    "        .options_list.value_counts()[:top_n_options]\n",
    "        .index\n",
    "        .to_list()\n",
    "    )\n",
    "\n",
    "    print(f\"Keeping the top {top_n_options} options by count: {most_common_options}\")\n",
    "\n",
    "    # drop all rows where options_list is not in most_common_options but keep empty rows\n",
    "    car_options_df = car_options_df[\n",
    "        (car_options_df.options_list.isin(most_common_options))\n",
    "        | (car_options_df.options_list.isna())\n",
    "    ]\n",
    "\n",
    "    # get the one hot encoded options for each ad by grouping opttions_list column \n",
    "    # into list and then exploding and one hot encoding\n",
    "    car_options_df = (\n",
    "        pd.get_dummies(car_options_df, columns=[\"options_list\"])\n",
    "        .groupby(\"unique_id\", as_index=False)\n",
    "        .sum(numeric_only=True)\n",
    "    )\n",
    "\n",
    "    return car_options_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = get_car_options(ads.df.copy(deep=True), top_n_options=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df[[\"source\", \"features\", \"major_options\", \"options_list\"]].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the count of top 30 options with stacked bars indicating count by source\n",
    "fig, ax = plt.subplots(figsize=(24, 12))\n",
    "sns.countplot(\n",
    "    y=\"options_list\",\n",
    "    # x=\"unique_id\",\n",
    "    data=ads.df.tail(100).explode(\"options_list\"), #.options_list.value_counts()[:30].reset_index(),\n",
    "    # hue=\"source\",\n",
    "    # palette=\"winter\",\n",
    "    # order=ads.df[[\"source\", \"options_list\"]].tail(100_000).explode(\"options_list\").options_list.value_counts()[:5].index,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Number of Ads\")\n",
    "ax.set_ylabel(\"Options\")\n",
    "ax.set_title(\"Top 30 Options by Count\", fontsize=23)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fwhleng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
