{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Price Modelling & Analysis\n",
    "\n",
    "Building on the inital round of training and model exploration, this notebook will focus on improving the MAPE and RMSE scores of the model. XGBoost will still be utilized but MAPE will be prioritized over RMSE and the 'options_list' feature will be added to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "SRC_PATH = cur_dir[: cur_dir.index(\"fortunato-wheels-engine\") + len(\"fortunato-wheels-engine\")]\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.append(SRC_PATH)\n",
    "\n",
    "from src.data.car_ads import CarAds\n",
    "from src.logs import get_logger\n",
    "from src.data.training_preprocessing import preprocess_ads_for_training\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "AZURE_MLFLOW_URI = os.environ.get(\"AZURE_MLFLOW_URI\")\n",
    "mlflow.set_tracking_uri(AZURE_MLFLOW_URI)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set(rc={\"figure.figsize\": (8, 12)})\n",
    "# set context to notebook\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "plt.rcParams[\"font.family\"] = \"sans serif\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in current car adds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-02 19:51:09,589 - src.data.car_ads - INFO - Loading car ads from /Users/jonah/Documents/fortunato/fortunato-wheels-engine/data/processed/car-ads-dump_2023-07-18.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonah/Documents/fortunato/fortunato-wheels-engine/src/data/car_ads.py:73: DtypeWarning: Columns (7,10,11,17,18,19,20,21,22,23,24,25,26,29,30,31,32,33,34,35,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.df = pd.read_csv(data_dump, parse_dates=[\"listed_date\"])\n"
     ]
    }
   ],
   "source": [
    "ads = CarAds()\n",
    "ads.get_car_ads(data_dump=os.path.join(SRC_PATH, \"data\", \"processed\", \"car-ads-dump_2023-07-18.csv\"))\n",
    "# ads.get_car_ads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-02 19:53:48,855 - src.data.car_ads - DEBUG - Keeping the top 50 options by count: ['backup-camera', 'bluetooth', 'alloy-wheels', 'apple-carplay-android-auto', 'heated-seats', 'navigation-system', 'sunroof-moonroof', 'leather-seats', 'remote-start', 'blind-spot-monitoring', 'cruise-control', 'parking-sensors', 'third-row-seating', 'quick-order-package', 'steel-wheels', 'air-conditioning', 'convenience-package', 'electronic-stability-control-(esc)', 'premium-package', '', 'push-button-start', 'isofix-(child-seat-anchor-points)', 'tow-package', 'usb', 'cd-player', 'appearance-package', 'emergency-brake-assist', 'power-package', 'technology-package', 'preferred-package', 'multi-zone-climate-control', 'sound-system', 'parking-assistant', 'lane-change-assist', 'cold-weather-package', 'heat-package', 'off-road-package', 'premium-wheels', 'se-package', 'chrome-wheels', 'adaptive-suspension', 'sport-package', 'suspension-package', 'trailer-package', 'radio', 'start-stop-system', 'electric-windows', 'cargo-package', 'le-package', 'distance-warning-system']\n",
      "2023-08-02 19:55:46,415 - src.data.car_ads - INFO - Vehicle option preprocessing complete, kept top 50 options by count.\n",
      "2023-08-02 19:55:46,422 - src.data.car_ads - INFO - Done preprocessing car ads, took 230s.\n"
     ]
    }
   ],
   "source": [
    "# inital preprocessing\n",
    "ads.preprocess_ads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-02 20:02:25,912 - src.data.training_preprocessing - INFO - Preprocessing ads for training, starting with 3779395 ads\n",
      "2023-08-02 20:02:54,161 - src.data.training_preprocessing - INFO - Preprocessing ads for training, ending with 1737985 ads\n"
     ]
    }
   ],
   "source": [
    "# select model features and split into train and test sets\n",
    "\n",
    "model_features = [\n",
    "    \"age_at_posting\",\n",
    "    \"mileage_per_year\",\n",
    "    \"make\",\n",
    "    \"model\",\n",
    "    \"price\",\n",
    "    \"wheel_system\",\n",
    "    \"options_list\"\n",
    "]\n",
    "\n",
    "\n",
    "# preprocess ads for training\n",
    "preprocessed_ads = preprocess_ads_for_training(\n",
    "    ads.df,\n",
    "    model_features=model_features, \n",
    "    exclude_new_vehicle_ads=True\n",
    ")\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    preprocessed_ads,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=preprocessed_ads[\"model\"],\n",
    ")\n",
    "\n",
    "# with features selected drop all with null values\n",
    "train_df = train_df[model_features].dropna().reset_index(drop=True)\n",
    "test_df = test_df[model_features].dropna().reset_index(drop=True)\n",
    "\n",
    "X_train = train_df.drop(columns=[\"price\"])\n",
    "y_train = train_df[\"price\"]\n",
    "X_test = test_df.drop(columns=[\"price\"])\n",
    "y_test = test_df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1390388 entries, 0 to 1390387\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   age_at_posting    1390388 non-null  int64  \n",
      " 1   mileage_per_year  1390388 non-null  float64\n",
      " 2   make              1390388 non-null  object \n",
      " 3   model             1390388 non-null  object \n",
      " 4   price             1390388 non-null  float64\n",
      " 5   wheel_system      1390388 non-null  object \n",
      " 6   options_list      1390388 non-null  object \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 74.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_at_posting</th>\n",
       "      <th>mileage_per_year</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>price</th>\n",
       "      <th>wheel_system</th>\n",
       "      <th>options_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>17145.000000</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Cruze</td>\n",
       "      <td>19597.0</td>\n",
       "      <td>FWD</td>\n",
       "      <td>[none-listed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>41345.600000</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Corolla</td>\n",
       "      <td>9123.0</td>\n",
       "      <td>FWD</td>\n",
       "      <td>[bluetooth, backup-camera]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>37570.666667</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Sonata</td>\n",
       "      <td>15601.0</td>\n",
       "      <td>FWD</td>\n",
       "      <td>[navigation-system, bluetooth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14539.333333</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Trax</td>\n",
       "      <td>20944.0</td>\n",
       "      <td>FWD</td>\n",
       "      <td>[navigation-system, bluetooth, backup-camera, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>30886.333333</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Fusion</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>FWD</td>\n",
       "      <td>[bluetooth, backup-camera]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_at_posting  mileage_per_year       make    model    price wheel_system  \\\n",
       "0               5      17145.000000  Chevrolet    Cruze  19597.0          FWD   \n",
       "1               5      41345.600000     Toyota  Corolla   9123.0          FWD   \n",
       "2               3      37570.666667    Hyundai   Sonata  15601.0          FWD   \n",
       "3               3      14539.333333  Chevrolet     Trax  20944.0          FWD   \n",
       "4               3      30886.333333       Ford   Fusion  20568.0          FWD   \n",
       "\n",
       "                                        options_list  \n",
       "0                                      [none-listed]  \n",
       "1                         [bluetooth, backup-camera]  \n",
       "2                     [navigation-system, bluetooth]  \n",
       "3  [navigation-system, bluetooth, backup-camera, ...  \n",
       "4                         [bluetooth, backup-camera]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Callable, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "\n",
    "# Class used from bryant1410L: https://github.com/scikit-learn/scikit-learn/issues/11309#issuecomment-1528042914\n",
    "\n",
    "class MultiHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Wraps `MultiLabelBinarizer` in a form that can work with `ColumnTransformer`. It makes it accept multiple inputs.\n",
    "\n",
    "    Note that the input `X` has to be a `pandas.DataFrame`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, binarizer_creator: Callable[[], Any] | None = None, dtype: npt.DTypeLike | None = None) -> None:\n",
    "        self.binarizer_creator = binarizer_creator or MultiLabelBinarizer\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self.binarizers = []\n",
    "        self.categories_ = self.classes_ = []\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: Any = None) -> MultiHotEncoder:  # noqa\n",
    "        self.columns = X.columns.to_list()\n",
    "\n",
    "        for column_name in X:\n",
    "            binarizer = self.binarizer_creator().fit(X[column_name])\n",
    "            self.binarizers.append(binarizer)\n",
    "            self.classes_.append(binarizer.classes_)  # noqa\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        if len(self.classes_) != X.shape[1]:\n",
    "            raise ValueError(f\"The fit transformer deals with {len(self.classes_)} columns \"\n",
    "                             f\"while the input has {X.shape[1]}.\")\n",
    "\n",
    "        return np.concatenate([binarizer.transform(X[c]).astype(self.dtype)\n",
    "                               for c, binarizer in zip(X, self.binarizers)], axis=1)\n",
    "\n",
    "    def get_feature_names_out(self, input_features: Sequence[str] = None) -> np.ndarray:\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        cats = self.categories_\n",
    "\n",
    "        if input_features is None:\n",
    "            input_features = self.columns\n",
    "        elif len(input_features) != len(self.categories_):\n",
    "            raise ValueError(f\"input_features should have length equal to number of features ({len(self.categories_)}),\"\n",
    "                             f\" got {len(input_features)}\")\n",
    "\n",
    "        return np.asarray([input_features[i] + \"_\" + str(t) for i in range(len(cats)) for t in cats[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"age_at_posting\", \"mileage_per_year\"]\n",
    "\n",
    "categorical_features = [\"model\", \"wheel_system\", \"make\"] \n",
    "\n",
    "multi_label_features = [\"options_list\"]\n",
    "\n",
    "# make column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "        (\"multi\", MultiHotEncoder(), multi_label_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 33)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train[:10]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 1, 1, 1, 0, 1, 0],\n",
       "       [0, 1, 1, 0, 0, 1, 1, 0, 0, 1]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "mlb.fit_transform(X_train['options_list'][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['air-conditioning', 'backup-camera', 'bluetooth', 'cruise-control',\n",
       "       'heated-seats', 'leather-seats', 'navigation-system',\n",
       "       'none-listed', 'remote-start', 'sunroof-moonroof'], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 1., 0., 1., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 0., 1., 1., 1., 0., 1., 0.],\n",
       "       [0., 1., 1., 0., 0., 1., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhe = MultiHotEncoder()\n",
    "\n",
    "mhe.fit_transform(pd.DataFrame(X_train['options_list'][:10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['options_list_air-conditioning', 'options_list_backup-camera',\n",
       "       'options_list_bluetooth', 'options_list_cruise-control',\n",
       "       'options_list_heated-seats', 'options_list_leather-seats',\n",
       "       'options_list_navigation-system', 'options_list_none-listed',\n",
       "       'options_list_remote-start', 'options_list_sunroof-moonroof'],\n",
       "      dtype='<U30')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# metrics = [\"neg_mean_absolute_percentage_error\",\"neg_root_mean_squared_error\", \"r2\"]\n",
    "metrics = [\"neg_mean_absolute_percentage_error\"]\n",
    "\n",
    "gbr_pipe = make_pipeline(\n",
    "    preprocessor,\n",
    "    GradientBoostingRegressor(\n",
    "        random_state=123\n",
    "    )\n",
    ")\n",
    "\n",
    "model_cv_results = pd.DataFrame(cross_validate(\n",
    "        gbr_pipe,\n",
    "        X_train[:100],\n",
    "        y_train[:100],\n",
    "        cv=5,\n",
    "        scoring=metrics,\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1,\n",
    "    )).agg([\"mean\", \"std\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.029618</td>\n",
       "      <td>0.000964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_mean_absolute_percentage_error</th>\n",
       "      <td>-0.339801</td>\n",
       "      <td>0.100092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_mean_absolute_percentage_error</th>\n",
       "      <td>-0.067729</td>\n",
       "      <td>0.007637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              mean       std\n",
       "fit_time                                  0.029618  0.000964\n",
       "score_time                                0.002594  0.000116\n",
       "test_neg_mean_absolute_percentage_error  -0.339801  0.100092\n",
       "train_neg_mean_absolute_percentage_error -0.067729  0.007637"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Hyperopt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first metric is the one to minimize\n",
    "metrics = [\"neg_mean_absolute_percentage_error\",\"neg_root_mean_squared_error\", \"r2\"]\n",
    "\n",
    "def objective(params):\n",
    "    classifier_type = params['type']\n",
    "    del params['type']\n",
    "    if classifier_type == 'gradient_boosting':\n",
    "        clf = GradientBoostingRegressor(**params)\n",
    "    elif classifier_type == 'xgboost':\n",
    "        clf = XGBRegressor(**params)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"regressor\", clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # manually run cross_validate and get train/test rmse, mape, and r2\n",
    "    model_cv_results = pd.DataFrame(cross_validate(\n",
    "        pipe,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=5,\n",
    "        scoring=metrics,\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1,\n",
    "    )).agg([\"mean\", \"std\"]).T\n",
    "\n",
    "\n",
    "    # log metrics to mlflow\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        # log train and test for each metric\n",
    "        for m in metrics:\n",
    "            mlflow.log_metric(f\"{m}_train_mean\", model_cv_results.loc[f\"train_{m}\"][\"mean\"])\n",
    "            mlflow.log_metric(f\"{m}_test_mean\", model_cv_results.loc[f\"test_{m}\"][\"mean\"])\n",
    "            mlflow.log_metric(f\"{m}_train_std\", model_cv_results.loc[f\"train_{m}\"][\"std\"])\n",
    "            mlflow.log_metric(f\"{m}_test_std\", model_cv_results.loc[f\"test_{m}\"][\"std\"])\n",
    "\n",
    "        # log params\n",
    "        mlflow.log_params(params)\n",
    "        # log the type of model\n",
    "        mlflow.log_param(\"model_type\", classifier_type)\n",
    "\n",
    "        fit_model = pipe.fit(X_train, y_train)\n",
    "\n",
    "        # log model\n",
    "        mlflow.sklearn.log_model(fit_model, \"model\", signature=infer_signature(X_train, y_train))\n",
    "\n",
    "    # make negative mape positive so it minimizes it\n",
    "    result = { 'loss': -model_cv_results.loc[\"test_\" + metrics[0]][\"mean\"], 'status': STATUS_OK}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'type': 'gradient_boosting',\n",
    "        'max_features': hp.choice('max_features', ['sqrt', 'log2']),\n",
    "        'max_depth': hp.uniformint('max_depth', 15, 30),\n",
    "        'min_samples_split': hp.uniformint('dtree_min_samples_split', 20, 40),\n",
    "        'n_estimators': hp.uniformint('n_estimators', 150, 300),\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"price-prediction-v3-gradboost\")\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "\n",
    "search_algorithm = tpe.suggest\n",
    "\n",
    "best_hyperparams = fmin(\n",
    "fn=objective, \n",
    "space=search_space,\n",
    "algo=search_algorithm,\n",
    "max_evals=2,\n",
    "trials= Trials())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin new training round with best hyperparmetes and log to mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to new best params\n",
    "# params = {\n",
    "#         'max_features': \"log2\",\n",
    "#         'max_depth': 25,\n",
    "#         'min_samples_split': 35,\n",
    "#         'n_estimators': 400\n",
    "#     }\n",
    "\n",
    "mlflow.set_experiment(\"price-prediction-v3\")\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", GradientBoostingRegressor(**params)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# manually run cross_validate and get train/test rmse, mape, and r2\n",
    "model_cv_results = pd.DataFrame(cross_validate(\n",
    "    pipe,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=metrics,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    ")).agg([\"mean\", \"std\"]).T\n",
    "\n",
    "\n",
    "# log metrics to mlflow\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # log train and test for each metric\n",
    "    for m in metrics:\n",
    "        mlflow.log_metric(f\"{m}_train_mean\", model_cv_results.loc[f\"train_{m}\"][\"mean\"])\n",
    "        mlflow.log_metric(f\"{m}_test_mean\", model_cv_results.loc[f\"test_{m}\"][\"mean\"])\n",
    "        mlflow.log_metric(f\"{m}_train_std\", model_cv_results.loc[f\"train_{m}\"][\"std\"])\n",
    "        mlflow.log_metric(f\"{m}_test_std\", model_cv_results.loc[f\"test_{m}\"][\"std\"])\n",
    "\n",
    "    # log params\n",
    "    mlflow.log_params(params)\n",
    "    # log the type of model\n",
    "    mlflow.log_param(\"model_type\", \"gradient_boosting\")\n",
    "\n",
    "    fit_model = pipe.fit(X_train, y_train)\n",
    "\n",
    "    # log model\n",
    "    mlflow.sklearn.log_model(fit_model, \"model\", signature=infer_signature(X_train, y_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fwhleng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
