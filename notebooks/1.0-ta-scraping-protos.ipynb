{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import random\n",
    "import time\n",
    "import datetime as dt\n",
    "import logging\n",
    "import json\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "SRC_PATH = cur_dir[: cur_dir.index(\"fortunato-wheels-engine\") + len(\"fortunato-wheels-engine\")]\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.append(SRC_PATH)\n",
    "\n",
    "from src.websites.kijiji import get_kijiji_car_ads, get_kijiji_car_ad_pages\n",
    "\n",
    "# Create a custom logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# create console handler and set level to debug\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "# create formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "# add formatter to ch\n",
    "ch.setFormatter(formatter)\n",
    "# add ch to logger\n",
    "if len(logger.handlers) != 0:\n",
    "    logger.handlers.clear()\n",
    "    print(\"Cleared exisiting handlers\")\n",
    "\n",
    "logger.addHandler(ch)\n",
    "logger.propagate = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kijiji Ad Scraping Development\n",
    "\n",
    "The approach taken to scrape Kijiji ads is to identify it's own internal API's which return the car ad details to the front end and use those instead of the raw HTML. This allows us to get the data in a structured format and avoid the need to parse the HTML.\n",
    "\n",
    "Two API's were identified:\n",
    "1. The search results page returns a JSON object with multiple car ad details\n",
    "   - this had the drawback that once we hit ~1000 ads the next_page_tokens stop being generated\n",
    "\n",
    "2. Individual car ad pages return a JSON object with the car ad details\n",
    "   - this had the drawback that we had to make a request for each car ad\n",
    "   - can exploit numerical exploration of the ad id's to get all the ads\n",
    "\n",
    "The primary challenges overcome when setting up this project were:\n",
    "- Figuring out the API's, general steps were:\n",
    "  1. Open chrome and go to the page and open More Tools --> Developer Tools\n",
    "  2. In there, go to Network and refresh the page\n",
    "  3. Select the Fetch/XHR tab and look at the Name of the items on the left, one will have some sort of ad/car id in it likely\n",
    "  4. Click through and inspect the Response tab to see the JSON object returned and find the data we want\n",
    "  5. Right click the Name and select Copy --> Copy as cURL (bash)\n",
    "  6. Paste it into a Postman session and run it to see the response\n",
    "  7. Deselect as much of the Headers as possible to get the cleanest request that still returns the response\n",
    "  8. Turn the results into header dictionary and request cookies dictionary\n",
    "  9. Setup the proxy from https://www.webshare.io/ as a dictionary\n",
    "  10. Pass all three parts as part of the request to the API like below\n",
    "\n",
    "```\n",
    "  res = session.get(url, proxies=proxy, headers=header, cookies=cookie)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "\n",
    "response = session.get(\"https://www.kijijiautos.ca\")\n",
    "\n",
    "cookies_dict = response.cookies.get_dict()\n",
    "cookies_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing assembly of the cookies\n",
    "cookie = {\n",
    "    \"mvcid\": cookies_dict[\"mvcid\"],\n",
    "    # \"mvcid\": \"804ca76e-48fe-4026-b099-134b2ccaee14\",\n",
    "    \"trty\": \"e\",\n",
    "    \"locale\": \"en-CA\",\n",
    "    \"GCLB\": cookies_dict[\"GCLB\"],\n",
    "    # \"GCLB\": \"CK_4wqOhg77K0gE\",\n",
    "    \"disableLoginPrompt\": \"true\",\n",
    "    \"location\": \"%7B%7D\",\n",
    "\n",
    "}\n",
    "\n",
    "header = {\n",
    "    \"url\": \"%2Fcars%2F\",\n",
    "    \"User-Agent\": \"com.ebay.kijiji.ca 6.5.0 (samsung SM-G930U; Android 8.0.0; en_US)\",\n",
    "    \"accept-language\": \"en-CA\",\n",
    "    \"Accept\": \"*/*\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    # \"Pragma\": \"no-cache\",\n",
    "    # \"Authorization\": \"Basic Y2FfYW5kcm9pZF9hcHA6YXBwQ2xAc3NpRmllZHMh\",\n",
    "    # \"Host\": \"mingle.kijiji.ca\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    # \"url\": \"%2Fcars%2F\",\n",
    "    \"referer\": \"https://www.kijijiautos.ca/cars/\",\n",
    "    \"x-client\": \"ca.move.web.app\",\n",
    "}\n",
    "\n",
    "# cookie = dict(Cookie = f\"mvcid={cookies_dict['mvcid']}; trty=e; locale=en-CA; GCLB={cookies_dict['GCLB']}; disableLoginPrompt=true; location=%7B%7D;\"\n",
    "#     \" c-client=ca.move.web.app;\")\n",
    "print(cookie)\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the proxy is correctly being used by checking the IP address in the response. If it's not, then the proxy is not being used and you'll get blocked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.websites.kijiji import get_proxy_details\n",
    "\n",
    "proxy = get_proxy_details()\n",
    "\n",
    "res = session.get(url=\"http://icanhazip.com\", headers=header, cookies=cookie)\n",
    "\n",
    "print(\"Without Proxy IP Address: \", res.text)\n",
    "\n",
    "res = session.get(url=\"http://icanhazip.com\", headers=header, cookies=cookie, proxies=proxy)\n",
    "\n",
    "print(\"With Proxy IP Address: \", res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that the proxy can be used by making a request to a website that is not blocked, like my website. If that works, then the proxy is working. Can view that realtime somebody s detected and location isn't Vanocuver in Google Analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original code from here: https://stackoverflow.com/questions/55582136/how-to-set-proxy-with-authentication-in-selenium-chromedriver-python\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "PROXY_HOST = \"2.56.119.93\"  # rotating proxy or host\n",
    "PROXY_PORT = 5074 # port\n",
    "PROXY_USER = 'qnjsnurv' # username\n",
    "PROXY_PASS = '7r9lv8kv4vwo' # password\n",
    "\n",
    "\n",
    "manifest_json = \"\"\"\n",
    "{\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"manifest_version\": 2,\n",
    "    \"name\": \"Chrome Proxy\",\n",
    "    \"permissions\": [\n",
    "        \"proxy\",\n",
    "        \"tabs\",\n",
    "        \"unlimitedStorage\",\n",
    "        \"storage\",\n",
    "        \"<all_urls>\",\n",
    "        \"webRequest\",\n",
    "        \"webRequestBlocking\"\n",
    "    ],\n",
    "    \"background\": {\n",
    "        \"scripts\": [\"background.js\"]\n",
    "    },\n",
    "    \"minimum_chrome_version\":\"22.0.0\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "background_js = \"\"\"\n",
    "var config = {\n",
    "        mode: \"fixed_servers\",\n",
    "        rules: {\n",
    "        singleProxy: {\n",
    "            scheme: \"http\",\n",
    "            host: \"%s\",\n",
    "            port: parseInt(%s)\n",
    "        },\n",
    "        bypassList: [\"localhost\"]\n",
    "        }\n",
    "    };\n",
    "\n",
    "chrome.proxy.settings.set({value: config, scope: \"regular\"}, function() {});\n",
    "\n",
    "function callbackFn(details) {\n",
    "    return {\n",
    "        authCredentials: {\n",
    "            username: \"%s\",\n",
    "            password: \"%s\"\n",
    "        }\n",
    "    };\n",
    "}\n",
    "\n",
    "chrome.webRequest.onAuthRequired.addListener(\n",
    "            callbackFn,\n",
    "            {urls: [\"<all_urls>\"]},\n",
    "            ['blocking']\n",
    ");\n",
    "\"\"\" % (PROXY_HOST, PROXY_PORT, PROXY_USER, PROXY_PASS)\n",
    "\n",
    "\n",
    "def get_chromedriver(use_proxy=False, user_agent=None):\n",
    "    # path = os.path.dirname(os.path.abspath(__file__))\n",
    "    path = os.getcwd()\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    if use_proxy:\n",
    "        pluginfile = 'proxy_auth_plugin.zip'\n",
    "\n",
    "        with zipfile.ZipFile(pluginfile, 'w') as zp:\n",
    "            zp.writestr(\"manifest.json\", manifest_json)\n",
    "            zp.writestr(\"background.js\", background_js)\n",
    "        chrome_options.add_extension(pluginfile)\n",
    "    if user_agent:\n",
    "        chrome_options.add_argument('--user-agent=%s' % user_agent)\n",
    "    driver = webdriver.Chrome(\n",
    "        # os.path.join(path, 'chromedriver'),\n",
    "        chrome_options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "def main():\n",
    "    driver = get_chromedriver(use_proxy=True)\n",
    "    # driver.get('https://www.google.com/search?q=my+ip+address')\n",
    "    driver.get('https://ty-andrews.com/')\n",
    "    time.sleep(60)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kj_url = 'https://www.kijijiautos.ca/' # consumer/srp/' #by-url?url=%2Fcars%2F'\n",
    "\n",
    "# res = session.get(url=\"https://www.kijijiautos.ca/consumer/srp/by-url?url=%2Fcars%2F\", headers=header, cookies=cookie)\n",
    "\n",
    "# get a page of car ads by make id 24100\n",
    "# res = session.get(url=\"https://www.kijijiautos.ca/consumer/srp/by-params?ms=24100\", headers=header, cookies=cookie)\n",
    "\n",
    "# get a single car ad by id 1500000000\n",
    "res = session.get(url=\"https://www.kijijiautos.ca/consumer/svc/a/28600002\", headers=header, cookies=cookie)\n",
    "# look at payload of request response\n",
    "res.json()\n",
    "\n",
    "j = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the page by page scraping save off a sample ad to use for testing of the parsing toolset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\n",
    "#     os.path.join(os.getcwd(), \"..\", \"data\", \"testing\", \"multi-page-ad-scraping-sample-ad.json\"),\n",
    "#     \"w\",\n",
    "# ) as f:\n",
    "#     json.dump(j[\"listings\"][\"items\"][0], f, indent=4)\n",
    "\n",
    "with open(\n",
    "    os.path.join(os.getcwd(), \"..\", \"data\", \"testing\", \"single-ad-scraping-sample-ad.json\"),\n",
    "    \"w\",\n",
    ") as f:\n",
    "    json.dump(j, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Scraping\n",
    "\n",
    "There are 2 methods for scraping, by the main page or by the individual ad pages. The main page method is faster but only returns the first ~1000 ads. The individual ad page method is slower but returns all the ads.\n",
    "\n",
    "Key pieces setup for both methods are:\n",
    "- After a batch of requests the user-agent is changed to avoid being blocked and a new session is created with new cookies\n",
    "- the time between subsequent requests is randomized to 1-2 times the previous response delay to hopefully not overload the server\n",
    "- `ad_id`'s that are not found are logged to a file `data/scraping-tracking/failed-ad-ids.json` with the response error code for debugging. This is used ensure they are not repeated later on subsequent runs of the scraping\n",
    "- Ads are uploaded in batches set in the primary scraping functions\n",
    "\n",
    "The two functions are:\n",
    "1. `get_kijiji_car_ads` - this uses individual ad_id's to get the ad details\n",
    "2. `get_kijiji_car_ad_pages` - this uses the main page to get the ad details in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "# collection.create_index([(\"ad_id\", pymongo.DESCENDING)], unique=True)\n",
    "last_ad_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# having pauses between batches of requests\n",
    "# last_ad_id = 28629000\n",
    "for _ in range(20):\n",
    "\n",
    "    max_requests = random.randint(600, 900)\n",
    "    df, json_dict, last_ad_id = get_kijiji_car_ads(\n",
    "        max_requests=max_requests,\n",
    "        batch_upload_size=50, \n",
    "        start_id=last_ad_id\n",
    "    )\n",
    "    sleep = random.randint(20, 40)\n",
    "    print(f\"Completed {max_requests} requests. Sleeping for {sleep} seconds...\")\n",
    "    time.sleep(sleep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape by car make web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"make\" in [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(\n",
    "        os.getcwd(), os.pardir, \"data\", \"scraping-tracking\", \"car-brands.json\"\n",
    "    )\n",
    ") as f:\n",
    "    car_manufacturers = json.load(f)\n",
    "\n",
    "# for car_make in car_manufacturers[\"car_makes\"]:\n",
    "for car_make in [\n",
    "        # # high volume batch, did 80 p, 20 per\n",
    "        # [24100, \"Toyota\"],\n",
    "        # [11000, \"Honda\"],\n",
    "\n",
    "        # Batch 2, 80p 40 per\n",
    "        # [23500, \"Subaru\"],\n",
    "        # [4, \"Polestar\"],\n",
    "        # [135, \"Tesla\"],\n",
    "        # [1900, \"Audi\"],\n",
    "        # [15200, \"Lexus\"],\n",
    "        # [25200, \"Volkswagen\"],\n",
    "\n",
    "        # [375, \"Acura\"],\n",
    "        # [3500, \"BMW\"],\n",
    "        # [25100, \"Volvo\"],\n",
    "\n",
    "        # low volume batch\n",
    "        # [4350, \"Bugatti\"],\n",
    "        # [14600, \"Lamborghini\"],\n",
    "        # [137, \"McLaren\"],\n",
    "        # [20100, \"Porsche\"],\n",
    "        # [3100, \"Bentley\"],\n",
    "        # [1700, \"Aston Martin\"],\n",
    "        # [21600, \"Rolls-Royce\"],\n",
    "        # [900, \"Alfa Romeo\"],\n",
    "        # [8600, \"Ferrari\"],\n",
    "        # [31859, \"Mercedes-AMG\"],\n",
    "\n",
    "        # [2, \"AMC\"],\n",
    "        # [266, \"AM General\"],\n",
    "        # [1950, \"Austin Healey\"],\n",
    "        # [268, \"Bricklin\"],\n",
    "        # [4400, \"Buick\"],\n",
    "        # [4700, \"Cadillac\"],\n",
    "        # [5600, \"Chevrolet\"],\n",
    "        # [5700, \"Chrysler\"],\n",
    "        # [6800, \"Daewoo\"],\n",
    "        # [7000, \"Daihatsu\"],\n",
    "        # [30002, \"Datsun\"],\n",
    "        # [7700, \"Dodge\"],\n",
    "        # [30003, \"Eagle\"],\n",
    "        # [8800, \"Fiat\"],\n",
    "        # [9000, \"Ford\"],\n",
    "        # [270, \"Genesis\"],\n",
    "        # [269, \"Geo\"],\n",
    "        # [9900, \"GMC\"],\n",
    "        # [11050, \"Hummer\"],\n",
    "        # [11600, \"Hyundai\"],\n",
    "        # [11650, \"Infiniti\"],\n",
    "        # [271, \"International Harvester\"],\n",
    "        # [11900, \"Isuzu\"],\n",
    "        # [12400, \"Jaguar\"],\n",
    "        # [12600, \"Jeep\"],\n",
    "        # [13200, \"Kia\"],\n",
    "        # [14800, \"Land Rover\"],\n",
    "        # [15500, \"Lincoln\"],\n",
    "        # [15900, \"Lotus\"],\n",
    "        # [16600, \"Maserati\"],\n",
    "        # [16700, \"Maybach\"],\n",
    "        # [16800, \"Mazda\"],\n",
    "        # [17200, \"Mercedes-Benz\"],\n",
    "        # [30010, \"Mercury\"],\n",
    "        # [17300, \"MG\"],\n",
    "        # [17500, \"MINI\"],\n",
    "        # [17700, \"Mitsubishi\"],\n",
    "        # [18700, \"Nissan\"],\n",
    "        # [18975, \"Oldsmobile\"],\n",
    "        # [19000, \"Opel\"],\n",
    "        # [1400, \"Other\"],\n",
    "        # [19300, \"Peugeot\"],\n",
    "        # [19800, \"Plymouth\"],\n",
    "        # [20000, \"Pontiac\"],\n",
    "        # [267, \"RAM\"],\n",
    "        # [20700, \"Renault\"],\n",
    "        # [21800, \"Saab\"],\n",
    "        # [30014, \"Saturn\"],\n",
    "        # [39, \"Scion\"],\n",
    "        # [30015, \"Shelby\"],\n",
    "        # [23000, \"Smart\"],\n",
    "        # [23600, \"Suzuki\"],\n",
    "        # [24400, \"Triumph\"],\n",
    "    ]:\n",
    "\n",
    "    make = car_make[1].lower().replace(\" \", \"-\")\n",
    "    make_number = car_make[0]\n",
    "\n",
    "    # scrape the kijiji car ads for each car make\n",
    "    df, json_dict, next_page_url = get_kijiji_car_ad_pages(\n",
    "        car_make=make,\n",
    "        make_number=make_number,\n",
    "        num_pages = 100,\n",
    "        page_size = 40, \n",
    "        batch_upload_size=20\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking how many items are in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.websites.kijiji import connect_to_database\n",
    "\n",
    "client, db, collection = connect_to_database()\n",
    "\n",
    "collection.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicates in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = list(\n",
    "        collection.aggregate([\n",
    "            {'$group': {\n",
    "                '_id': {\n",
    "                    'make': \"$make\",\n",
    "                    'model': \"$model\",\n",
    "                    'year': \"$year\",\n",
    "                    \"title\": \"$title\",\n",
    "                    \"color\": \"$color\",\n",
    "                    \"trim\": \"$trim\",\n",
    "                    \"price\": \"$price\",\n",
    "                    \"seller.sellerForeignId\": \"$seller.sellerForeignId\",\n",
    "                },\n",
    "                'uniqueIds': {'$addToSet': \"$ad_id\"},\n",
    "                'count': {'$sum': 1}\n",
    "                }\n",
    "            },\n",
    "            {'$match': { \n",
    "                'count': {\"$gt\": 1}\n",
    "                }\n",
    "            },\n",
    "            {'$sort': {\n",
    "                'count': -1\n",
    "                }\n",
    "            }\n",
    "        ])\n",
    "    )\n",
    "duplicates_df = pd.DataFrame(duplicates)\n",
    "duplicates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(duplicates_df._id.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = list(\n",
    "        collection.aggregate([\n",
    "            {'$group': {\n",
    "                '_id': {\n",
    "                    'ad_id': \"$ad_id\",\n",
    "                },\n",
    "                'uniqueIds': {'$addToSet': \"$ad_id\"},\n",
    "                'count': {'$sum': 1}\n",
    "                }\n",
    "            },\n",
    "            {'$match': { \n",
    "                'count': {\"$gt\": 1}\n",
    "                }\n",
    "            },\n",
    "            {'$sort': {\n",
    "                'count': -1\n",
    "                }\n",
    "            }\n",
    "        ])\n",
    "    )\n",
    "duplicates_df = pd.DataFrame(duplicates)\n",
    "duplicates_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from random import randint\n",
    "\n",
    "import pymongo\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_STRING = os.environ.get(\"COSMOS_CONNECTION_STRING\")\n",
    "DB_NAME = os.environ.get(\"ADS_DB_NAME\")\n",
    "COLLECTION_NAME = os.environ.get(\"KIJIJI_COLLECTION_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(CONNECTION_STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database if it doesn't exist\n",
    "db = client[DB_NAME]\n",
    "\n",
    "if DB_NAME not in client.list_database_names():\n",
    "    # Create a database with 400 RU throughput that can be shared across\n",
    "    # the DB's collections\n",
    "    db.command({\"customAction\": \"CreateDatabase\", \"offerThroughput\": 400})\n",
    "    print(\"Created db '{}' with shared throughput.\\n\".format(DB_NAME))\n",
    "else:\n",
    "    print(\"Using database: '{}'.\\n\".format(DB_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create collection if it doesn't exist\n",
    "collection = db[COLLECTION_NAME]\n",
    "if COLLECTION_NAME not in db.list_collection_names():\n",
    "    # Creates a unsharded collection that uses the DBs shared throughput\n",
    "    db.command(\n",
    "        {\"customAction\": \"CreateCollection\", \"collection\": COLLECTION_NAME}\n",
    "    )\n",
    "    print(\"Created collection '{}'.\\n\".format(COLLECTION_NAME))\n",
    "else:\n",
    "    print(\"Using collection: '{}'.\\n\".format(COLLECTION_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Query for documents in the collection\"\"\"\n",
    "print(\"Cars with price < 20,000':\\n\")\n",
    "results = pd.DataFrame(collection.find(\n",
    "    {\"price\": {\"$lt\": 20000}}\n",
    ").sort(\n",
    "    \"price\", pymongo.ASCENDING\n",
    ").limit(5))\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using/Visualizing the Data\n",
    "\n",
    "To start using we can query like above and then convert to a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "# enable notebook mode\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ads = pd.DataFrame(collection.find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ads.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many ads do we have?\n",
    "print(f\"No. of Ads: {len(all_ads)}\")\n",
    "# how many ads from each manufacturer do we have?\n",
    "all_ads.make.value_counts()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ads.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ads.loc[all_ads.price > 1_000_000, [\"price\", \"title\", \"make\", \"model\", \"year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ads = all_ads.loc[all_ads.price < 500_000, :]\n",
    "# mileage readings over a million km divide by 10\n",
    "all_ads.loc[all_ads.mileage > 1_000_000, \"mileage\"] = all_ads.loc[all_ads.mileage > 1_000_000, \"mileage\"] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ads = all_ads.assign(\n",
    "    date_time = pd.to_datetime(all_ads.created, unit=\"s\", origin=\"unix\")\n",
    ")\n",
    "all_ads = all_ads.assign(\n",
    "    year = all_ads.date_time.dt.year,\n",
    "    month = all_ads.date_time.dt.month,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of prices\n",
    "fig = px.histogram(\n",
    "    all_ads, \n",
    "    x=\"price\", \n",
    "    # color=\"make\",\n",
    "    nbins=100,\n",
    ").update_layout(\n",
    "    title=\"Distribution of Prices\",\n",
    "    xaxis_title=\"Price\",\n",
    "    yaxis_title=\"Count\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=18,\n",
    "        color=\"#7f7f7f\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ads.loc[all_ads.mileage > 500_000, [\"mileage\", \"title\", \"make\", \"model\", \"year\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_ads.loc[all_ads.mileage < 1000, [\"mileage\", \"title\", \"make\", \"model\", \"year\", \"condition\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of prices\n",
    "fig = px.histogram(\n",
    "    all_ads.loc[(all_ads.mileage < 500_000) & (all_ads.mileage > 10), :], \n",
    "    x=\"mileage\", \n",
    "    # color=\"make\",\n",
    "    nbins=200,\n",
    ").update_layout(\n",
    "    title=\"Distribution of Mileages\",\n",
    "    xaxis_title=\"Odometer Reading\",\n",
    "    yaxis_title=\"Count\",\n",
    "    # xaxis_range=[0, 500_000],\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=18,\n",
    "        color=\"#7f7f7f\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of prices\n",
    "fig = px.scatter(\n",
    "    all_ads, \n",
    "    x=\"year\", \n",
    "    y = \"price\",\n",
    "    color=\"make\",\n",
    ").update_layout(\n",
    "    title=\"Distribution of Price\",\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"Price (CAD)\",\n",
    "    # xaxis_range=[0, 500_000],\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=18,\n",
    "        color=\"#7f7f7f\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [\n",
    "    df.loc[df.category == cat, \"price\"].tolist() \n",
    "    for cat in df.category.unique() \n",
    "    if len(df.loc[df.category == cat, \"price\"]) > 5\n",
    "]\n",
    "cat_list = [\n",
    "    cat\n",
    "    for cat in df.category.unique() \n",
    "    if len(df.loc[df.category == cat, \"price\"]) > 5\n",
    "]\n",
    "\n",
    "# # Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(data_list, cat_list)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "\n",
    "# Add histogram data\n",
    "x1 = np.random.randn(200) - 2\n",
    "x2 = np.random.randn(200)\n",
    "x3 = np.random.randn(200) + 2\n",
    "x4 = np.random.randn(200) + 4\n",
    "\n",
    "# Group data together\n",
    "hist_data = [x1, x2, x3, x4]\n",
    "\n",
    "group_labels = ['Group 1', 'Group 2', 'Group 3', 'Group 4']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels, bin_size=.2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INserting DOcuments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_be_inserted = []\n",
    "# for i in range(0,1):\n",
    "    \n",
    "#     ad =  j[\"listings\"][\"items\"][i]\n",
    "\n",
    "#     parsed_ad = parse_single_vehicle_ad(ad)\n",
    "\n",
    "#     # parsed_ad[\"price\"] = 12345\n",
    "\n",
    "#     # check if ad already exists\n",
    "#     if collection.find_one({\"ad_id\" : parsed_ad[\"ad_id\"]}):\n",
    "        \n",
    "#         # if it does exist, check if prices have changed\n",
    "#         existing_ad = collection.find_one({\"ad_id\" : parsed_ad[\"ad_id\"]})\n",
    "#         if existing_ad[\"price\"] != parsed_ad[\"price\"]:\n",
    "#             upda\n",
    "#     else:\n",
    "#         to_be_inserted.append(parsed_ad)\n",
    "\n",
    "# print(len(to_be_inserted))\n",
    "\n",
    "# if len(to_be_inserted) > 0:\n",
    "#     collection.insert_many(to_be_inserted)\n",
    "#     print(f\"Successfully inserted {len(to_be_inserted)} ads into the database.\")\n",
    "#     to_be_inserted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.kjAds.create_index([(\"ad_id\", pymongo.DESCENDING)], unique=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('fwhleng')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef3b2fd4ca8766ea5a25df4f99c28bc55f7f21963f7ba7f8512d2f4c9a470227"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
