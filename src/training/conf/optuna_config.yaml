# Useufl resources:
# Optuna hydra example w/ Reinf Lear: https://github.com/Marc-Velay/hydra_optuna_tutorial



defaults:
  - model: xgboost
  - model/search_spaces@hydra.sweeper.params: ${model}
  - _self_
  - override hydra/sweeper: optuna
  - override hydra/sweeper/sampler: tpe

load_data:
  params:
    year_range: None
    make: None
    model: None
    sources: 
      - cargurus
      - kijiji
    # data_dump: None
  preprocess: 
    top_n_options: 50

preprocess:
  model_feats:
    target:
      - price
    numeric:
      - age_at_posting
      - mileage_per_year
    categorical:    
      - make
      - model
      - wheel_system
    multi_label:
      - options_list
  exclude: True
  min_num: 1000 
  max_age: 20
  min_price: 1000
  max_price: 250000
  test_size: 0.2

hydra:
  sweeper:
    _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
    direction: maximize
    study_name: car-price-prediction
    storage: null
    n_trials: 3
    n_jobs: 1
    # seed: 42
    # choose Optuna hyperparameter sampler
    # you can choose bayesian sampler (tpe), random search (without optimization), grid sampler, and others
    # docs: https://optuna.readthedocs.io/en/stable/reference/samplers.html
    sampler:
      _target_: optuna.samplers.TPESampler
      seed: 1234
      n_startup_trials: 0 # number of random sampling runs before optimization starts

# mlflow:
  # regressor: xgboost
  # metrics: # first metric is the one to minimize
  # - neg_mean_absolute_percentage_error
  # - neg_root_mean_squared_error
  # - r2
  

mlflow:
  exp_name: "sandbox"
  evals: 1
  log_to_mlflow: True
  metrics: # first metric is the one to minimize
  - neg_mean_absolute_percentage_error
  - neg_root_mean_squared_error
  - r2

xgboost:
  n_estimators: range(150, 300, step=5)
  max_depth: range(3, 10)
  learning_rate: range(0.001, 0.3)
  subsample: range(0.1,1.0)
  colsample_bytree: range(0.1,1.0)
  gamma: range(0, 0.4)
  min_child_weight: range(1, 10)

search_space:
  gradient_boosting:
    max_features:
      - choice
      - ["sqrt", "log2"]
    max_depth:
      - uniformint
      - 15
      - 30
    min_samples_split:
      - uniformint
      - 20
      - 40
    n_estimators:
      - uniformint
      - 150
      - 300
  xgboost:
    max_depth:
      - uniformint
      - 15
      - 40
    min_child_weight:
      - uniformint
      - 1
      - 10
    subsample:
      - uniform
      - 0.5
      - 1
    n_estimators:
      - uniformint
      - 150
      - 400
    learning_rate:
      - uniform
      - 0.01
      - 0.2
    gamma:
      - uniform
      - 0.1
      - 1
  rf:
    max_depth:
      - uniformint
      - 5
      - 50
    max_features:
      - choice
      - ["sqrt", "log2"]
    min_samples_split:
      - uniform
      - 0.1
      - 1
  ridge:
    alpha:
      - uniform
      - 0.1
      - 100

